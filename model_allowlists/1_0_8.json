{
  "models": [
    {
      "name": "Gemma3-1B-IT",
      "modelId": "litert-community/Gemma3-1B-IT",
      "modelFile": "gemma3-1b-it-int4.litertlm",
      "description": "A variant of [google/Gemma-3-1B-IT](https://huggingface.co/google/Gemma-3-1B-IT) with 4-bit quantization ready for deployment on Android using [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM/blob/main/kotlin/README.md).",
      "sizeInBytes": 584417280,
      "minDeviceMemoryInGb": 6,
      "commitHash": "42d538a932e8d5b12e6b3b455f5572560bd60b2c",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 1024,
        "accelerators": "gpu,cpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"],
      "bestForTaskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "Qwen2.5-0.5B-Instruct",
      "modelId": "litert-community/Qwen2.5-0.5B-Instruct",
      "modelFile": "qwen2.5-0.5b-instruct-dynamic_int8.litertlm",
      "description": "A variant of [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct) ready for deployment on Android using [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM/blob/main/kotlin/README.md).",
      "sizeInBytes": 546308096,
      "minDeviceMemoryInGb": 2,
      "commitHash": "main",
      "defaultConfig": {
        "topK": 20,
        "topP": 0.8,
        "temperature": 0.7,
        "maxTokens": 1280,
        "accelerators": "cpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"]
    }
  ]
}
